---
title: "Land cover data for species distribution modeling"
author: "Jeff Oliver"
date: "2021-11-12"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Summary

An investigation into the use of MODIS land-cover data for species distribution 
models.

# Setup

## Dependencies

The work below uses additional package to download, visualize, and analyze the 
data.

```{r load-libraries, echo = FALSE}
suppressPackageStartupMessages({
  library(raster)      # reading and transforming geospatial data
  library(ggplot2)     # data visualization
  library(dplyr)       # data wrangling
  library(terra)       # dealing with hdf-formatted files
  library(MODIStsp)    # downloading land cover data
})
```

```{r load-libraries-display, eval = FALSE}
library(raster)      # reading and transforming geospatial data
library(ggplot2)     # data visualization
library(dplyr)       # data wrangling
library(terra)       # dealing with hdf-formatted files
library(MODIStsp)    # downloading land cover data
```

## Earthdata access

To access the data, you'll need to register with NASA's Earthdata system at 
[https://urs.earthdata.nasa.gov/users/new](https://urs.earthdata.nasa.gov/users/new). 
After registering, also be sure to navigate to your 
[profile page](https://urs.earthdata.nasa.gov/profile), click the on the 
Applications menu and the Authorized Apps submenu. Click the "Approve More 
Applications" button near the bottom of the page and click the "Authorize" 
button in the row labeled "LP DAAC Data Pool". Make a note of your username and 
password, as we will need those when downloading the data. Note the password 
is not super-securely stored by NASA, so don't use one that is especially 
important to you (I'm not going to lecture anyone about never re-using 
passwords - we all do it).

# Data retrieval

In this example, we use land cover data available from
[MODIS](https://modis.gsfc.nasa.gov/data/dataprod/). There are many means of 
categorizing land cover, and in this example we use the land cover scheme of 
the International Geosphere-Biosphere Programme (IGBP) that identifies 17 
classes of land cover. There are two options for retrieving this land cover 
data:

1. Direct download
2. Use MODIStsp package

## Direct download

The entirety of the land cover data from MODIS can be downloaded for years 
2010-2019 from [https://e4ftl01.cr.usgs.gov/MOTA/MCD12C1.006/](https://e4ftl01.cr.usgs.gov/MOTA/MCD12C1.006/). 
For this example, we will just use the 2019 data available at [https://e4ftl01.cr.usgs.gov/MOTA/MCD12C1.006/2019.01.01/](https://e4ftl01.cr.usgs.gov/MOTA/MCD12C1.006/2019.01.01/) 
by downloading the file MCD12C1.A2019001.006.2020220162300.hdf. The file is 
fairly large (1.2 GB), so it might take a few minutes to download. After it 
downloads, place this file in a "data" directory in your project. 

The downloaded file is global in extent and uses a bit of an old projection 
system. So the next bit of code limits the data to the area of interest and 
re-projects it into the commonly used WGS84 projection.

```{r hdf-investigation}
# Location of hdf file with land cover data
hdf_file <- "data/MCD12C1.A2019001.006.2020220162300.hdf"

# Look to see what layers are in that hdf file
terra::describe(hdf_file, sds = TRUE)
```

The table above shows us that we are interested in the first sub-dataset, which
has the IGBP land-cover classification information. When we load in the data, 
we can pull in just that one sub-dataset of interest. We can then see what 
coordinate reference system (CRS) or projection is being used with 
`terra::crs()`:

```{r hdf-projection}
# Load in the first subdataset only, which has IGBP land cover type
r <- terra::rast(hdf_file, subds = 1)

# What projection is being used?
terra::crs(r, describe = TRUE)
```

Well that's not the most useful information, but it turns out this vague 
projection is [nearly identical to a more common one, NAD27](https://community.esri.com/t5/data-management-questions/converting-from-clarke-1866-to-wgs-1984/td-p/255165). So we are going to tell R to go ahead and re-categorize the 
projection as NAD27.

```{r update-crs}
# Start by making it clear which EPSG:4008 projection this is (may not be 
# entirely necessary)
terra::crs(r) <- "epsg:4008"

# Set the projection to something we know (NAD27 is apparently close); the EPSG
# identifier for NAD27 is 4267
terra::crs(r) <- "epsg:4267"
```

Now R considers these data as NAD27, but we need to re-project the data into 
yet _another_ coordinate system (well, we may not have to, but NAD27 is a bit 
out of date). While we are at it, we can crop the data down to a smaller 
geographic area so it doesn't take up as much memory.

```{r re-project}
# Crop to western US + Mexico
crop_to <- raster::extent(x = c(-120, -104, 22, 49))
r <- raster::crop(x = r, y = crop_to)

# Convert to a RasterLayer, which is easier to work with
r_nad27 <- raster::raster(r)

# Rename what the data are (otherwise it just uses the file name)
names(r_nad27) <- "IGBP_Land_Cover_Type"

# Convert the projection to good old WGS84
r_wgs84 <- raster::projectRaster(from = r_nad27, 
                                 method = "ngb", # For categorical data
                                 crs = sp::CRS(projargs = "+init=epsg:4326"))

# Crop this to Sonoran desert dimensions
sonoran <- raster::extent(x = c(-114, -109, 26, 35))
r_wgs84 <- raster::crop(x = r_wgs84, y = sonoran)

# Finally, save to a file
raster::writeRaster(x = r_wgs84,
                    filename = "data/Sonoran_land_cover.tif",
                    overwrite = TRUE)
```


If you download the data this way, you can skip the next section and head 
straight to [Data quality check](#data-quality-check).

## Use MODIStsp package

The R package MODIStsp provides a way to download portions of the land cover 
data, instead of the full, global coverage. In my experience, I encountered 
quite a few problems with accessing data from servers, so I would only 
recommend this approach if the direct download option above doesn't work.

If you want to get details about data availability, you can run:

```{r modis-check}
MODIStsp::MODIStsp_get_prodlayers("MCD12Q1")
```

It's that first band that we want ("LC1", or "Land Cover Type 1 (IGBP)*"). To 
download the data, we use the `MODIStsp()` function from the MODIStsp package. 
Much of the code for downloading and visualizing these data from the example at 
[https://rspatialdata.github.io/land_cover.html](https://rspatialdata.github.io/land_cover.html).
Here's where you'll need to add your usename and password that you used to 
register for NASA's Earthdata site. In the example below, I stored them in a 
pair of plain text files called earthdata-username.txt and 
earthdata-password.txt. I then read in the values and stored them in variables 
`username` and `password` respectively.

```{r load-credentials, eval = FALSE}
username <- scan(file = "../keys/earthdata-username.txt", what = character())
password <- scan(file = "../keys/earthdata-password.txt", what = character())
```

You could also do this in the console if you don't want to store your username 
and/or password in files (replacing `<INSERT USERNAME HERE>` and 
`<INSERT PASSWORD HERE>` with your actual username and password):

```{r assign-credentials, eval = FALSE}
# Run in the console:
username <- "<INSERT USERNAME HERE>"
password <- "<INSERT PASSWORD HERE>"
```

We will download land cover data for a box that roughly encapsulates the 
Sonoran desert. The code below downloads the data to a folder called "data", so 
be sure that you have created such a folder first (i.e. `dir.create("data")`).

```{r download-sonoran-raster, eval = FALSE}
# Boundaries of interest (left, bottom, right, top); here we use very rough 
# coordinates for the Sonoran desert
bounds <- c(-114, 26, -109, 35)

# Need to specify which projection to use; we do this with the WKT (Well Known 
# Text) string for the WGS 84 projection. A terrifying thing, but it works. 
# Using paste0 so it all fits in this document
wkt_proj <- paste0('GEOGCS["WGS 84",DATUM["WGS_1984",SPHEROID["WGS84",6378137,',
                   '298.257223563,AUTHORITY["EPSG","7030"]],AUTHORITY["EPSG",',
                   '"6326"]],PRIMEM["Greenwich",0,AUTHORITY["EPSG","8901"]],',
                   'UNIT["degree",0.01745329251994328,AUTHORITY["EPSG","9122"]',
                   '],AUTHORITY["EPSG","4326"]]')

# Query server for data of interest
MODIStsp::MODIStsp(gui = FALSE,
                   out_folder = "data",
                   out_folder_mod = "data",
                   selprod = "LandCover_Type_Yearly_500m (MCD12Q1)",
                   bandsel = "LC1", 
                   start_date = "2019.01.01", 
                   end_date = "2019.12.31", 
                   user = username,
                   password = password,
                   verbose = FALSE, # set to true if you want to see details
                   reprocess = TRUE,
                   spatmeth = "bbox",
                   bbox = bounds,
                   out_projsel = "User Defined",
                   output_proj = wkt_proj,
                   out_format = "GTiff")
```

The servers where these data live are notorious for timing out. Sometimes it 
takes a few times of running the above code for it to actually work. If you see 
multiple lines of 

`Error in curl::curl_fetch_memory(url, handle = handle): Timeout was reached`

try running the `MODIStsp()` command again.

# Data quality check

After downloading the data, we can do a reality check and plot the land cover 
data. We will need to read the data into memory and transform it into a data 
frame for easier plotting with ggplot. In the code below, we'll assume you 
used the first option ([Direct download](#direct-download)).

```{r plot-raster}
# Load in raster from file
LC_raster <- raster::raster(x = "data/Sonoran_land_cover.tif")

# Convert data to categorical (R thinks it is continuous)
# LC_raster <- raster::as.factor(x = LC_raster)

# Convert to a data frame for plotting and make sure we set the land cover 
# types to a 17-level factor (want to do this because our subset of data does 
# not include all land cover types, but we need the factor to have all 17 
# levels so we can assign land cover types appropriately)
LC_df <- as.data.frame(LC_raster, xy = TRUE, na.rm = TRUE) %>%
  rename(lc_type = Sonoran_land_cover) %>%
  mutate(lc_type = factor(lc_type, levels = 0:16))

# Re-level data
levels(LC_df$lc_type) <- c("Water Bodies",
                           "Evergreen needleleaf forests",
                           "Evergreen broadleaf forests",
                           "Deciduous needleleaf forests",
                           "Deciduous broadleaf forests",
                           "Mixed forests",
                           "Closed shrublands",
                           "Open shrublands",
                           "Woody savannas",
                           "Savannas",
                           "Grasslands",
                           "Permanent wetlands",
                           "Croplands",
                           "Urban and built-up lands",
                           "Cropland/natural vegetation mosaics",
                           "Snow and ice",
                           "Barren")

# Visualize using ggplot2
lc_plot <- ggplot(data = LC_df, 
                  mapping = aes(x = x, y = y, fill = lc_type)) + 
  geom_raster() +
  scale_fill_viridis_d(name = "Land Cover Type") + # the color scheme
  labs(subtitle = "Land cover 2019",
       x = "Longitude",
       y = "Latitude") +
  theme_minimal() +
  theme(legend.text = element_text(size = 8))
print(lc_plot)
```

# Species distribution modeling

Stay tuned!