---
title: "Land cover data for species distribution modeling"
author: "Jeff Oliver"
date: "2021-11-12"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Summary

An investigation into the use of MODIS land-cover data for species distribution 
models.

# Setup

## Dependencies

The work below uses additional package to download, visualize, and analyze the 
data.

```{r load-libraries, echo = FALSE}
suppressPackageStartupMessages({
  library(raster)      # reading and transforming geospatial data
  library(ggplot2)     # data visualization
  library(dplyr)       # data wrangling
  library(MODIStsp)    # downloading land cover data
})
```

```{r load-libraries-display, eval = FALSE}
library(raster)      # reading and transforming geospatial data
library(ggplot2)     # data visualization
library(dplyr)       # data wrangling
library(MODIStsp)    # downloading land cover data
```

## Earthdata access

To access the data, you'll need to register with NASA's Earthdata system at 
[https://urs.earthdata.nasa.gov/users/new](https://urs.earthdata.nasa.gov/users/new). 
After registering, also be sure to navigate to your 
[profile page](https://urs.earthdata.nasa.gov/profile), click the on the 
Applications menu and the Authorized Apps submenu. Click the "Approve More 
Applications" button near the bottom of the page and click the "Authorize" 
button in the row labeled "LP DAAC Data Pool". Make a note of your username and 
password, as we will need those when downloading the data. Note the password 
is not super-securely stored by NASA, so don't use one that is especially 
important to you (I'm not going to lecture anyone about never re-using 
passwords - we all do it).

# Data retrieval

In this example, we use land cover data available from
[MODIS](https://modis.gsfc.nasa.gov/data/dataprod/). There are many means of 
categorizing land cover, and in this example we use the land cover scheme of 
the International Geosphere-Biosphere Programme (IGBP) that identifies 17 
classes of land cover. There are two options for retrieving this land cover 
data:

1. Direct download
2. Use MODIStsp package

## Direct download

The entirety of the land cover data from MODIS can be downloaded for years 
2010-2019 from [](). For example, the 2019 data are available at [https://e4ftl01.cr.usgs.gov/MOTA/MCD12C1.006/2019.01.01/](https://e4ftl01.cr.usgs.gov/MOTA/MCD12C1.006/2019.01.01/) by downloading the file MCD12C1.A2019001.006.2020220162300.hdf.
The file is fairly large (1.2 GB), so it might take a few minutes to download. 
After it downloads, place this file in a "data" directory in your project. 

```{r hdf-to-geotiff}
# Location of hdf with land cover data
hdf_file <- "data/MCD12C1.A2019001.006.2020220162300.hdf"
# Look to see what layers are in that hdf file
terra::describe(hdf_file, sds = TRUE)

# Load in the first subdataset only, which has IGBP land cover type; we'll 
# only pull out data for western US + Mexico here
r <- terra::rast(hdf_file, subds = 1)

# What projection is being used?
terra::crs(r, describe = TRUE)

# Start by making it clear which EPSG:4008 projection this is (may not be 
# entirely necessary)
terra::crs(r) <- "epsg:4008"

# Set the projection to something we know (NAD27 is apparently close)
# https://community.esri.com/t5/data-management-questions/converting-from-clarke-1866-to-wgs-1984/td-p/255165
terra::crs(r) <- "epsg:4267"

# Crop to western US + Mexico
crop_to <- raster::extent(x = c(-120, -104, 22, 49))
r <- raster::crop(x = r, y = crop_to)

# Write raster to file
terra::writeRaster(x = r, filename = "data/lc_NAD27.tif", overwrite = TRUE)

# Read that one in with raster::raster
r_nad27 <- raster::raster(x = "data/lc_NAD27.tif")

# Rename what the data are (otherwise it just uses the file name)
names(r_nad27) <- "IGBP_Land_Cover_Type"

# Convert the projection to good old WGS84 with sp::spTransform
r_wgs84 <- raster::projectRaster(from = r_nad27, 
                                 method = "ngb", # For categorical data
                                 crs = sp::CRS(projargs = "+init=epsg:4326"))

# Finally, crop this to Sonoran desert dimensions, save to a file and remove 
# the temporary NAD27 file
sonoran <- raster::extent(x = c(-114, -109, 26, 35))
r_wgs84 <- raster::crop(x = r_wgs84, y = sonoran)

raster::writeRaster(x = r_wgs84,
                    filename = "data/Sonoran_land_cover.tif",
                    overwrite = TRUE)
file_rm <- file.remove("data/lc_NAD27.tif")
```


If 
you download the data this way, you can skip the next section and head straight 
to [Data quality check](#data-quality-check).

## Use MODIStsp package

The R package MODIStsp provides a way to download portions of the land cover 
data, instead of the full, global coverage. In my experience, I encountered 
quite a few problems with accessing data from servers, so I would only 
recommend this approach if the direct download option above doesn't work.

If you want to get details about data availability, you can run:

```{r modis-check}
MODIStsp::MODIStsp_get_prodlayers("MCD12Q1")
```

It's that first band that we want ("LC1", or "Land Cover Type 1 (IGBP)*"). To 
download the data, we use the `MODIStsp()` function from the MODIStsp package. 
Much of the code for downloading and visualizing these data from the example at 
[https://rspatialdata.github.io/land_cover.html](https://rspatialdata.github.io/land_cover.html).
Here's where you'll need to add your usename and password that you used to 
register for NASA's Earthdata site. In the example below, I stored them in a 
pair of plain text files called earthdata-username.txt and 
earthdata-password.txt. I then read in the values and stored them in variables 
`username` and `password` respectively.

```{r load-credentials, eval = FALSE}
username <- scan(file = "../keys/earthdata-username.txt", what = character())
password <- scan(file = "../keys/earthdata-password.txt", what = character())
```

You could also do this in the console if you don't want to store your username 
and/or password in files (replacing `<INSERT USERNAME HERE>` and 
`<INSERT PASSWORD HERE>` with your actual username and password):

```{r assign-credentials, eval = FALSE}
# Run in the console:
username <- "<INSERT USERNAME HERE>"
password <- "<INSERT PASSWORD HERE>"
```

We will download land cover data for a box that roughly encapsulates the 
Sonoran desert. The code below downloads the data to a folder called "data", so 
be sure that you have created such a folder first (i.e. `dir.create("data")`).

```{r download-sonoran-raster, eval = FALSE}
# Boundaries of interest (left, bottom, right, top); here we use very rough 
# coordinates for the Sonoran desert
bounds <- c(-114, 26, -109, 35)

# Need to specify which projection to use; we do this with the WKT (Well Known 
# Text) string for the WGS 84 projection. A terrifying thing, but it works. 
# Using paste0 so it all fits in this document
wkt_proj <- paste0('GEOGCS["WGS 84",DATUM["WGS_1984",SPHEROID["WGS84",6378137,',
                   '298.257223563,AUTHORITY["EPSG","7030"]],AUTHORITY["EPSG",',
                   '"6326"]],PRIMEM["Greenwich",0,AUTHORITY["EPSG","8901"]],',
                   'UNIT["degree",0.01745329251994328,AUTHORITY["EPSG","9122"]',
                   '],AUTHORITY["EPSG","4326"]]')

# Query server for data of interest
MODIStsp::MODIStsp(gui = FALSE,
                   out_folder = "data",
                   out_folder_mod = "data",
                   selprod = "LandCover_Type_Yearly_500m (MCD12Q1)",
                   bandsel = "LC1", 
                   start_date = "2019.01.01", 
                   end_date = "2019.12.31", 
                   user = username,
                   password = password,
                   verbose = FALSE, # set to true if you want to see details
                   reprocess = TRUE,
                   spatmeth = "bbox",
                   bbox = bounds,
                   out_projsel = "User Defined",
                   output_proj = wkt_proj,
                   out_format = "GTiff")
```

The servers where these data live are notorious for timing out. Sometimes it 
takes a few times of running the above code for it to actually work. If you see 
multiple lines of 

`Error in curl::curl_fetch_memory(url, handle = handle): Timeout was reached`

try running the `MODIStsp()` command again.

# Data quality check

After downloading the data, we can do a reality check and plot the land cover 
data. We will need to read the data into memory and transform it into a data 
frame for easier plotting with ggplot.

```{r plot-raster}
# Load in raster from file
LC_raster <- raster::raster(x = "data/Sonoran_land_cover.tif")

# Convert data to categorical (R thinks it is continuous)
# LC_raster <- raster::as.factor(x = LC_raster)

# Convert to a data frame for plotting
LC_df <- as.data.frame(LC_raster, xy = TRUE, na.rm = TRUE) %>%
  rename(lc_type = Sonoran_land_cover) %>%
  mutate(lc_type = as.factor(lc_type))

# Re-level data
levels(LC_df$lc_type) <- c("Water Bodies",
                           "Evergreen needleleaf forests",
                           "Evergreen broadleaf forests",
                           "Deciduous needleleaf forests",
                           "Deciduous broadleaf forests",
                           "Mixed forests",
                           "Closed shrublands",
                           "Open shrublands",
                           "Woody savannas",
                           "Savannas",
                           "Grasslands",
                           "Permanent wetlands",
                           "Croplands",
                           "Urban and built-up lands",
                           "Cropland/natural vegetation mosaics",
                           "Snow and ice",
                           "Barren")

# Visualize using ggplot2
lc_plot <- ggplot(data = LC_df, 
                  mapping = aes(x = x, y = y, fill = lc_type)) + 
  geom_raster() +
  scale_fill_viridis_d(name = "Land Cover Type") + # the color scheme
  labs(subtitle = "Land cover 2016",
       x = "Longitude",
       y = "Latitude") +
  theme_minimal() +
  theme(legend.text = element_text(size = 8))
print(lc_plot)





IGBP_raster <- raster::raster(x = "data/LandCover_Type_Yearly_500m_v6/LC1/MCD12Q1_LC1_2019_001.tif")

# Convert to a data frame for plotting
IGBP_df <- as.data.frame(IGBP_raster, xy = TRUE, na.rm = TRUE) %>%
  mutate(MCD12Q1_LC1_2019_001 = as.factor(round(MCD12Q1_LC1_2019_001)))

# Reset rownames so they are numbered, starting at 1
rownames(IGBP_df) <- c()

# Renaming IGBP classification levels, since incoming data just enumerates them
# 0-16
levels(IGBP_df$MCD12Q1_LC1_2019_001) <- c("Evergreen needleleaf forests",
                                          "Evergreen broadleaf forests",
                                          "Deciduous needleleaf forests",
                                          "Deciduous broadleaf forests",
                                          "Mixed forests",
                                          "Closed shrublands",
                                          "Open shrublands",
                                          "Woody savannas",
                                          "Savannas",
                                          "Grasslands",
                                          "Permanent wetlands",
                                          "Croplands",
                                          "Urban and built-up lands",
                                          "Cropland/natural vegetation mosaics",
                                          "Snow and ice",
                                          "Barren",
                                          "Water bodies")
# Visualising using ggplot2
lc_plot <- ggplot(data = IGBP_df, 
                  mapping = aes(x = x, y = y, fill = MCD12Q1_LC1_2019_001)) + 
  geom_raster() +
  scale_fill_viridis_d(name = "Land Cover Type") + # the color scheme
  labs(subtitle = "Land cover 2019",
       x = "Longitude",
       y = "Latitude") +
  theme_minimal() +
  theme(legend.text = element_text(size = 8))
print(lc_plot)
```

# Species distribution modeling

Stay tuned!